{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding transition probabilities to random walks\n",
    "\n",
    "This notebook creates transition probability matrices based on user movement between pages for a *1)* directed graph, and an *2)* undirected graph. Performs repeated random walks using the probability matrices for both the directed and undirected graph, and saves both outputs as a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(A, G, steps, seed, p=False):\n",
    "    '''\n",
    "    A is an adjacency matrix, or a transition probability matrix. These should be CSR sparse matrices.\n",
    "    Set p=True if using a transition probability matrix.\n",
    "    G is a networkx graph.\n",
    "    steps is the number of steps to take in the random walk.\n",
    "    seed is a page slug for your starting node in the random walk. E.g. \"/set-up-business\" \n",
    "    \n",
    "    returns a numpy array of node ids visited during the random walk.\n",
    "    can return numpy array of nodes with their data if nodeData == True\n",
    "    '''\n",
    "\n",
    "    # set a seed node\n",
    "    foundSeed = False\n",
    "    for current_node_index, node in enumerate(G.nodes(data=True)):\n",
    "        if node[1][\"properties\"][\"name\"] == seed:\n",
    "            foundSeed = True\n",
    "            break\n",
    "    \n",
    "    if not foundSeed:\n",
    "        return []\n",
    "\n",
    "    # list of nodes visited during the random walk\n",
    "    visited = [current_node_index]\n",
    "    \n",
    "    transition_probs = None\n",
    "\n",
    "    for _ in range(steps):\n",
    "\n",
    "        # identify neighbours of current node\n",
    "        neighbours = np.nonzero(A[current_node_index])[1]\n",
    "\n",
    "        # if reached an absorbing state, i.e. no neighbours, then terminate the random walk\n",
    "        if neighbours.size == 0:\n",
    "            #print(\"Reached absorbing state after\", step, \"steps\")\n",
    "            visited = list(set(visited))\n",
    "            return np.array(G.nodes())[visited]\n",
    "        \n",
    "        # if using transition probabilities, get them\n",
    "        if p:\n",
    "            transition_probs = A[current_node_index].toarray()[0, neighbours]\n",
    "        \n",
    "        # select the index of next node to transition to\n",
    "        current_node_index = np.random.choice(neighbours, p=transition_probs)\n",
    "\n",
    "        # maintain record of the path taken by the random walk\n",
    "        visited.append(current_node_index)\n",
    "    \n",
    "    # return unique pages visited\n",
    "    visited = list(set(visited))\n",
    "        \n",
    "    return np.array(G.nodes())[visited]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import randomwalks as rw\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create transition matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './functional_directed_graph_uk.gpickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-746fecd6f653>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get directed graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./functional_directed_graph_uk.gpickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create array with edge weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madjacency_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"edgeWeight\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-771>\u001b[0m in \u001b[0;36mread_gpickle\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\networkx\\utils\\decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(func_to_be_decorated, *args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m             \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dispatch_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m             \u001b[0mclose_fobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './functional_directed_graph_uk.gpickle'"
     ]
    }
   ],
   "source": [
    "# Get directed graph\n",
    "G = nx.read_gpickle(\"./functional_directed_graph_uk.gpickle\")\n",
    "\n",
    "# Create array with edge weight\n",
    "T = nx.adjacency_matrix(G, weight=\"edgeWeight\").todense()\n",
    "T_array = np.array(T)\n",
    "\n",
    "# Transform edge weight into probabilities\n",
    "\n",
    "# Normalisation\n",
    "sum_of_rows = T_array.sum(axis=1)\n",
    "T_probs = T_array / sum_of_rows[:, np.newaxis]\n",
    "\n",
    "# Rows with only 0s = nan. Replace nan values with 1/Tarray.shape[0]\n",
    "np.nan_to_num(T_probs, nan=1 / T_array.shape[0], copy=False)\n",
    "\n",
    "# Convert into a transition matrix (for random walks function)\n",
    "T_directed = csr_matrix(T_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undirected graph\n",
    "*G.to_undirected() can not be used to control what data the undirected edges get, therefore we need to create a new graph and sum the edge weights*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the edges with weight = 0\n",
    "G_undirected = nx.Graph()\n",
    "G_undirected.add_nodes_from(G.nodes(data=True))\n",
    "G_undirected.add_edges_from(G.edges, edgeWeight=0)\n",
    "\n",
    "# Sum weights for each edge\n",
    "for u, v, d in G.edges(data=True):\n",
    "    G_undirected[u][v][\"edgeWeight\"] += d[\"edgeWeight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array with edge weight\n",
    "T_undirected = nx.adjacency_matrix(G_undirected, weight=\"edgeWeight\").todense()\n",
    "T_undirected_array = np.array(T_undirected)\n",
    "\n",
    "# Normalisation\n",
    "sum_of_rows = T_undirected_array.sum(axis=1)\n",
    "T_undirected_probs = T_undirected_array / sum_of_rows[:, np.newaxis]\n",
    "np.nan_to_num(T_undirected_probs, nan=1 / T_undirected_array.shape[0], copy=False)\n",
    "\n",
    "# Convert into a transition matrix (for random walks function)\n",
    "T_undirected = csr_matrix(T_undirected_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seeds from where random walks will be initialised\n",
    "seeds = (\n",
    "    \"/browse/visas-immigration/work-visas\",\n",
    "    \"/browse/visas-immigration/what-you-need-to-do\",\n",
    "    \"/check-uk-visa\",\n",
    "    \"/apply-to-come-to-the-uk\",\n",
    "    \"/contact-ukvi-inside-outside-uk\",\n",
    "    \"/skilled-worker-visa\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the graph to make it compliant with existing random walk functions\n",
    "# i.e. add the path to a name property and set the index to be a number\n",
    "for index, data in G.nodes(data=True):\n",
    "    data[\"properties\"] = dict()\n",
    "    data[\"properties\"][\"name\"] = index\n",
    "\n",
    "G = nx.convert_node_labels_to_integers(\n",
    "    G, first_label=0, ordering=\"default\", label_attribute=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_directed = rw.repeat_random_walks(\n",
    "    steps=100,\n",
    "    repeats=100,\n",
    "    T=T_directed,\n",
    "    G=G,\n",
    "    seed_pages=seeds,\n",
    "    proba=True,\n",
    "    combine=\"union\",\n",
    "    level=1,\n",
    "    n_jobs=1,\n",
    ")\n",
    "page_scores_directed = rw.page_freq_path_freq_ranking(results_directed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undirected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat the graph to make it compliant with existing random walk functions\n",
    "# i.e. add the path to a name property and set the index to be a number\n",
    "for index, data in G_undirected.nodes(data=True):\n",
    "    data[\"properties\"] = dict()\n",
    "    data[\"properties\"][\"name\"] = index\n",
    "\n",
    "G_undirected = nx.convert_node_labels_to_integers(\n",
    "    G_undirected, first_label=0, ordering=\"default\", label_attribute=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_undirected = rw.repeat_random_walks(\n",
    "    steps=100,\n",
    "    repeats=100,\n",
    "    T=T_undirected,\n",
    "    G=G_undirected,\n",
    "    seed_pages=seeds,\n",
    "    proba=True,\n",
    "    combine=\"union\",\n",
    "    level=1,\n",
    "    n_jobs=1,\n",
    ")\n",
    "page_scores_undirected = rw.page_freq_path_freq_ranking(results_undirected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document supertypes\n",
    "news_and_comms_doctypes = {\n",
    "    \"medical_safety_alert\",\n",
    "    \"drug_safety_update\",\n",
    "    \"news_article\",\n",
    "    \"news_story\",\n",
    "    \"press_release\",\n",
    "    \"world_location_news_article\",\n",
    "    \"world_news_story\",\n",
    "    \"fatality_notice\",\n",
    "    \"fatality_notice\",\n",
    "    \"tax_tribunal_decision\",\n",
    "    \"utaac_decision\",\n",
    "    \"asylum_support_decision\",\n",
    "    \"employment_appeal_tribunal_decision\",\n",
    "    \"employment_tribunal_decision\",\n",
    "    \"employment_tribunal_decision\",\n",
    "    \"service_standard_report\",\n",
    "    \"cma_case\",\n",
    "    \"decision\",\n",
    "    \"oral_statement\",\n",
    "    \"written_statement\",\n",
    "    \"authored_article\",\n",
    "    \"correspondence\",\n",
    "    \"speech\",\n",
    "    \"government_response\",\n",
    "    \"case_study\",\n",
    "}\n",
    "\n",
    "service_doctypes = {\n",
    "    \"completed_transaction\",\n",
    "    \"local_transaction\",\n",
    "    \"form\",\n",
    "    \"calculator\",\n",
    "    \"smart_answer\",\n",
    "    \"simple_smart_answer\",\n",
    "    \"place\",\n",
    "    \"licence\",\n",
    "    \"step_by_step_nav\",\n",
    "    \"transaction\",\n",
    "    \"answer\",\n",
    "    \"guide\",\n",
    "}\n",
    "\n",
    "guidance_and_reg_doctypes = {\n",
    "    \"regulation\",\n",
    "    \"detailed_guide\",\n",
    "    \"manual\",\n",
    "    \"manual_section\",\n",
    "    \"guidance\",\n",
    "    \"map\",\n",
    "    \"calendar\",\n",
    "    \"statutory_guidance\",\n",
    "    \"notice\",\n",
    "    \"international_treaty\",\n",
    "    \"travel_advice\",\n",
    "    \"promotional\",\n",
    "    \"international_development_fund\",\n",
    "    \"countryside_stewardship_grant\",\n",
    "    \"esi_fund\",\n",
    "    \"business_finance_support_scheme\",\n",
    "    \"statutory_instrument\",\n",
    "    \"hmrc_manual\",\n",
    "    \"standard\",\n",
    "}\n",
    "\n",
    "policy_and_engage_doctypes = {\n",
    "    \"impact_assessment\",\n",
    "    \"policy_paper\",\n",
    "    \"open_consultation\",\n",
    "    \"policy_paper\",\n",
    "    \"closed_consultation\",\n",
    "    \"consultation_outcome\",\n",
    "    \"policy_and_engagement\",\n",
    "}\n",
    "\n",
    "research_and_stats_doctypes = {\n",
    "    \"dfid_research_output\",\n",
    "    \"independent_report\",\n",
    "    \"research\",\n",
    "    \"statistics\",\n",
    "    \"national_statistics\",\n",
    "    \"statistics_announcement\",\n",
    "    \"national_statistics_announcement\",\n",
    "    \"official_statistics_announcement\",\n",
    "    \"statistical_data_set\",\n",
    "    \"official_statistics\",\n",
    "}\n",
    "\n",
    "transparency_doctypes = {\n",
    "    \"transparency\",\n",
    "    \"corporate_report\",\n",
    "    \"foi_release\",\n",
    "    \"aaib_report\",\n",
    "    \"raib_report\",\n",
    "    \"maib_report\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with `pagePath`: `documentType`, `sessionHitsAll`, `entranceHit`, `exitHit`, `entranceAndExitHit`\n",
    "df_dict = {\n",
    "    info[\"properties\"][\"name\"]: [\n",
    "        info[\"documentType\"],\n",
    "        info[\"sessionHitsAll\"],\n",
    "        info[\"entranceHit\"],\n",
    "        info[\"exitHit\"],\n",
    "        info[\"entranceAndExitHit\"],\n",
    "        info[\"sessionHits\"],\n",
    "    ]\n",
    "    for node, info in G.nodes(data=True)\n",
    "}\n",
    "df_dict = {\n",
    "    k: v for (k, v) in df_dict.items() if k in page_scores_directed[\"pagePath\"].tolist()\n",
    "}\n",
    "df_info = (\n",
    "    pd.DataFrame.from_dict(\n",
    "        df_dict,\n",
    "        orient=\"index\",\n",
    "        columns=[\n",
    "            \"documentType\",\n",
    "            \"sessionHitsAll\",\n",
    "            \"entranceHit\",\n",
    "            \"exitHit\",\n",
    "            \"entranceAndExitHit\",\n",
    "            \"sessionHits\",\n",
    "        ],\n",
    "    )\n",
    "    .rename_axis(\"pagePath\")\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with document supertypes\n",
    "document_type_dict = dict.fromkeys(list(set(df_info[\"documentType\"])))\n",
    "\n",
    "for docType, docSupertype in document_type_dict.items():\n",
    "    if docType in news_and_comms_doctypes:\n",
    "        document_type_dict[docType] = \"news and communication\"\n",
    "\n",
    "    elif docType in service_doctypes:\n",
    "        document_type_dict[docType] = \"services\"\n",
    "\n",
    "    elif docType in guidance_and_reg_doctypes:\n",
    "        document_type_dict[docType] = \"guidance and regulation\"\n",
    "\n",
    "    elif docType in policy_and_engage_doctypes:\n",
    "        document_type_dict[docType] = \"policy and engagement\"\n",
    "\n",
    "    elif docType in research_and_stats_doctypes:\n",
    "        document_type_dict[docType] = \"research and statistics\"\n",
    "\n",
    "    elif docType in transparency_doctypes:\n",
    "        document_type_dict[docType] = \"transparency\"\n",
    "\n",
    "    else:\n",
    "        document_type_dict[docType] = \"other\"\n",
    "\n",
    "df_docSuper = pd.DataFrame(\n",
    "    document_type_dict.items(), columns=[\"documentType\", \"documentSupertype\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dfs\n",
    "df_merged = pd.merge(page_scores_directed, df_info, on=\"pagePath\")\n",
    "df_merged = pd.merge(df_merged, df_docSuper, how=\"left\")\n",
    "\n",
    "# Reoder and rename df columns\n",
    "df_merged = df_merged[\n",
    "    [\n",
    "        \"pagePath\",\n",
    "        \"documentType\",\n",
    "        \"documentSupertype\",\n",
    "        \"sessionHitsAll\",\n",
    "        \"entranceHit\",\n",
    "        \"exitHit\",\n",
    "        \"entranceAndExitHit\",\n",
    "        \"sessionHits\",\n",
    "        \"tfdf_max\",\n",
    "    ]\n",
    "]\n",
    "df_merged = df_merged.rename(\n",
    "    columns={\n",
    "        \"pagePath\": \"page path\",\n",
    "        \"documentType\": \"document type\",\n",
    "        \"documentSupertype\": \"document supertype\",\n",
    "        \"sessionHitsAll\": \"number of sessions that visit this page\",\n",
    "        \"entranceHit\": \"number of sessions where this page is an entrance hit\",\n",
    "        \"exitHit\": \"number of sessions where this page is an exit hit\",\n",
    "        \"entranceAndExitHit\": \"number of sessions where this page is both an entrance and exit hit\",\n",
    "        \"sessionHits\": \"all sessions that visit this page, regardless of the session visiting a seed page\",\n",
    "        \"tfdf_max\": \"how frequent the page occurs in the whole user journey\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save df\n",
    "df_merged.to_csv(\"../../outputs/pages_ranked_directed_uk.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undirected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with `pagePath`: `documentType`, `sessionHitsAll`, `entranceHit`, `exitHit`, `entranceAndExitHit`\n",
    "df_dict = {\n",
    "    info[\"properties\"][\"name\"]: [\n",
    "        info[\"documentType\"],\n",
    "        info[\"sessionHitsAll\"],\n",
    "        info[\"entranceHit\"],\n",
    "        info[\"exitHit\"],\n",
    "        info[\"entranceAndExitHit\"],\n",
    "        info[\"sessionHits\"],\n",
    "    ]\n",
    "    for node, info in G_undirected.nodes(data=True)\n",
    "}\n",
    "df_dict = {\n",
    "    k: v\n",
    "    for (k, v) in df_dict.items()\n",
    "    if k in page_scores_undirected[\"pagePath\"].tolist()\n",
    "}\n",
    "df_info = (\n",
    "    pd.DataFrame.from_dict(\n",
    "        df_dict,\n",
    "        orient=\"index\",\n",
    "        columns=[\n",
    "            \"documentType\",\n",
    "            \"sessionHitsAll\",\n",
    "            \"entranceHit\",\n",
    "            \"exitHit\",\n",
    "            \"entranceAndExitHit\",\n",
    "            \"sessionHits\",\n",
    "        ],\n",
    "    )\n",
    "    .rename_axis(\"pagePath\")\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with document supertypes\n",
    "document_type_dict = dict.fromkeys(list(set(df_info[\"documentType\"])))\n",
    "\n",
    "for docType, docSupertype in document_type_dict.items():\n",
    "    if docType in news_and_comms_doctypes:\n",
    "        document_type_dict[docType] = \"news and communication\"\n",
    "\n",
    "    elif docType in service_doctypes:\n",
    "        document_type_dict[docType] = \"services\"\n",
    "\n",
    "    elif docType in guidance_and_reg_doctypes:\n",
    "        document_type_dict[docType] = \"guidance and regulation\"\n",
    "\n",
    "    elif docType in policy_and_engage_doctypes:\n",
    "        document_type_dict[docType] = \"policy and engagement\"\n",
    "\n",
    "    elif docType in research_and_stats_doctypes:\n",
    "        document_type_dict[docType] = \"research and statistics\"\n",
    "\n",
    "    elif docType in transparency_doctypes:\n",
    "        document_type_dict[docType] = \"transparency\"\n",
    "\n",
    "    else:\n",
    "        document_type_dict[docType] = \"other\"\n",
    "\n",
    "df_docSuper = pd.DataFrame(\n",
    "    document_type_dict.items(), columns=[\"documentType\", \"documentSupertype\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dfs\n",
    "df_merged = pd.merge(page_scores_undirected, df_info, on=\"pagePath\")\n",
    "df_merged = pd.merge(df_merged, df_docSuper, how=\"left\")\n",
    "\n",
    "# Reoder and rename df columns\n",
    "df_merged = df_merged[\n",
    "    [\n",
    "        \"pagePath\",\n",
    "        \"documentType\",\n",
    "        \"documentSupertype\",\n",
    "        \"sessionHitsAll\",\n",
    "        \"entranceHit\",\n",
    "        \"exitHit\",\n",
    "        \"entranceAndExitHit\",\n",
    "        \"sessionHits\",\n",
    "        \"tfdf_max\",\n",
    "    ]\n",
    "]\n",
    "df_merged = df_merged.rename(\n",
    "    columns={\n",
    "        \"pagePath\": \"page path\",\n",
    "        \"documentType\": \"document type\",\n",
    "        \"documentSupertype\": \"document supertype\",\n",
    "        \"sessionHitsAll\": \"number of sessions that visit this page\",\n",
    "        \"entranceHit\": \"number of sessions where this page is an entrance hit\",\n",
    "        \"exitHit\": \"number of sessions where this page is an exit hit\",\n",
    "        \"entranceAndExitHit\": \"number of sessions where this page is both an entrance and exit hit\",\n",
    "        \"sessionHits\": \"all sessions that visit this page, regardless of the session visiting a seed page\",\n",
    "        \"tfdf_max\": \"how frequent the page occurs in the whole user journey\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save df\n",
    "df_merged.to_csv(\"../../outputs/pages_ranked_undirected_uk.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b7996c91914f58fa5b6ecdeb9ea962f20a305b909dd8998d946195ffc4b7996"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
